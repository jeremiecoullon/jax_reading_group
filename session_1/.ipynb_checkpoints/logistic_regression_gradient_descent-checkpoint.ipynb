{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from jax import jit, vmap, grad, value_and_grad\n",
    "from jax import numpy as np\n",
    "from jax.scipy.special import logsumexp\n",
    "from scipy.special import logsumexp as onp_logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for logistic regression: find the MAP\n",
    "\n",
    "*Thursday 15th October 2020*\n",
    "\n",
    "**Summary:**\n",
    "1. `vmap`: how it works\n",
    "2. generate data for logistic regression\n",
    "3. build posterior\n",
    "4. behaviour of `jit` & `block_until_ready()`\n",
    "5. comparison to numpy\n",
    "6. gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. vmap\n",
    "\n",
    "#### First example: square elements in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 801 ms, sys: 128 ms, total: 929 ms\n",
      "Wall time: 929 ms\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "big_num = int(1e7)\n",
    "\n",
    "%time a = [elem*elem for elem in range(big_num)]\n",
    "\n",
    "print(a[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "batch_square = vmap(square, in_axes=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.8 ms, sys: 28.4 ms, total: 67.1 ms\n",
      "Wall time: 22.4 ms\n",
      "[ 0  1  4  9 16 25 36 49 64 81]\n"
     ]
    }
   ],
   "source": [
    "%time batch_square(np.arange(big_num))[0].block_until_ready()\n",
    "\n",
    "print(batch_square(np.arange(big_num))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.27272727272727"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# speedup\n",
    "930/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: Jax doesn't always take any inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_square(range(big_num))\n",
    "\n",
    "# batch_square(list(range(big_num)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second example: sum of dot products\n",
    "\n",
    "\n",
    "$\\sum^N U_i^T U_i$ with $U \\in \\mathcal{R^{N \\times D}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: (1000, 10)\n",
      "Shape of batch_dot(U): (1000,)\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "D = 10\n",
    "\n",
    "U = onp.random.uniform(size=(N,D))\n",
    "print(f\"Shape of U: {U.shape}\")\n",
    "\n",
    "def norm_square(x):\n",
    "    return np.dot(x,x)\n",
    "\n",
    "batch_dot = vmap(norm_square, in_axes=(0,))\n",
    "\n",
    "\n",
    "# now simply pass in U\n",
    "print(f\"Shape of batch_dot(U): {batch_dot(U).shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([3.5023053, 2.524429 , 3.431289 , 4.3207164, 3.062355 ,\n",
       "             3.4152622, 2.0468721, 3.1359453, 3.581743 , 3.5813015],            dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dot(U)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check that it worked:\n",
      "3.5023053\n",
      "3.5023053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCheck that it worked:\")\n",
    "print(batch_dot(U)[0])\n",
    "print(np.dot(U[0,:], U[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### benchmark vs list comprehension\n",
    "\n",
    "- increase N: numpy grows, and Jax stays the same for a bit, then grows\n",
    "- increase D: Jax is slower than numpy in some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "D = 10\n",
    "\n",
    "U = onp.random.uniform(size=(N,D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.45 ms, sys: 3.63 ms, total: 8.08 ms\n",
      "Wall time: 5.3 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time a = [onp.dot(x,x) for x in U]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.08 ms, sys: 2.41 ms, total: 7.48 ms\n",
      "Wall time: 4.91 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(2.6831276, dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time batch_dot(U)[0].block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other applications of vmap:\n",
    "\n",
    "- Calculating the loss/log-likelihood/etc.. at each data point in optimisation/MCMC\n",
    "- computing the entries of a gram matrix \n",
    "- Running MCMC chains in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate data\n",
    "\n",
    "Setup from [SG-MCMC paper](https://arxiv.org/abs/1907.06986) (Nemeth and Fearnhead)\n",
    "\n",
    "- Matrix of covariates $\\textbf{X} \\in \\mathcal{R}^{N\\times d}$, and vector responses: $\\textbf{y} = \\{ y_i \\}_1^N$\n",
    "- Parameters: $\\theta \\in \\mathcal{R^d}$\n",
    "\n",
    "\n",
    "**Model:** \n",
    "\n",
    "- $y_i = \\text{Bernoulli}(p_i)$ with $p_i = \\frac{1}{ 1+\\exp(-\\theta^T x_i)}$\n",
    "- Prior: $\\theta \\sim \\mathcal{N}(0, \\Sigma_{\\theta})$ with $\\Sigma_{\\theta} = 10\\textbf{I}_d$\n",
    "- Likelihood: $p(X,y | \\theta) = \\Pi^N p_i^{y_i}(1-p_i)^{y_i}$\n",
    "\n",
    "**Generate data:** \n",
    "- $x_i \\sim \\mathcal{N}(0, \\Sigma_x)$ with $\\Sigma_x^{(i,j)} = \\text{Unif}(-\\rho, \\rho)^{|i-j|}$ and $\\rho =0.4$\n",
    "- Sample true parameter from the prior: $\\theta_{0} \\sim \\mathcal{N}(0, \\Sigma_{\\theta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data\n",
      "done\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "dim = 10\n",
    "N = 10000\n",
    "rho = 0.4\n",
    "onp.random.seed(0)\n",
    "\n",
    "def genCovMat(d, rho):\n",
    "    \"Generate a correlated Covariance matrix with 1s on diagonal\"\n",
    "    Sigma0 = onp.diag(onp.ones(d))\n",
    "    for i in range(1,d):\n",
    "        for j in range(0, i):\n",
    "            Sigma0[i,j] = onp.random.uniform(-rho, rho)**(i-j)\n",
    "            Sigma0[j,i] = Sigma0[i,j]\n",
    "    \n",
    "    return Sigma0\n",
    "\n",
    "print(\"generating data\")\n",
    "theta_true = onp.random.normal(size=dim)*onp.sqrt(10)\n",
    "\n",
    "covX = genCovMat(dim, rho)\n",
    "X = onp.random.multivariate_normal(mean=onp.zeros(dim), cov=covX, size=N)\n",
    "\n",
    "def logistic(theta, x):\n",
    "    return 1/(1+onp.exp(-onp.dot(theta, x)))\n",
    "\n",
    "p_array = onp.array([logistic(theta_true, elem) for elem in X])\n",
    "y_data = onp.array([onp.random.binomial(n=1,p=elem) for elem in p_array])\n",
    "print(\"done\")\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. build posterior\n",
    "\n",
    "\n",
    "Likelihood: $p(X,y | \\theta) = \\Pi^N p_i^{y_i}(1-p_i)^{y_i}$\n",
    "\n",
    "\n",
    "So the log-likelihood for each data point is: \n",
    "\n",
    "\\begin{align}\n",
    "l_i(\\theta) &= y_i \\log(p_i) + (1-y_i)\\log(1-p_i) \\\\\n",
    " &= -\\log \\left[ 1 + \\exp\\left((1-2y_i) \\theta^T x_i \\right) \\right]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Comments:**\n",
    "\n",
    "- everything is composable. Example: `jit(vmap(jit(grad(myfun))))` is valid (though have two `jit`'s are not useful)\n",
    "- test the code below: having jit on `loglikelihood`, `log_prior`, `log_post`, and `grad_log_post` is the same as having just once on `grad_log_post`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(theta, x_val, y_val):\n",
    "    return -logsumexp(np.array([0., (1.-2.*y_val)*np.dot(theta, x_val)]))\n",
    "\n",
    "\n",
    "batch_loglik = vmap(loglikelihood, in_axes=(None, 0,0))\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    return -(0.5/10)*np.dot(theta,theta)\n",
    "\n",
    "\n",
    "def log_post(theta):\n",
    "    return log_prior(theta) + np.sum(batch_loglik(theta, X, y_data), axis=0)\n",
    "\n",
    "\n",
    "grad_log_post = jit(grad(log_post))\n",
    "\n",
    "val_and_grad_log_post = jit(value_and_grad(log_post))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-0.00280452, dtype=float32)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikelihood(theta_true, X[0,:], y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-2.8045154e-03, -5.5907592e-05, -3.3350980e-01, ...,\n",
       "             -5.3260446e-04, -1.9376041e-01, -9.3832105e-02],            dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loglik(theta_true, X, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theta_true[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.38 ms, sys: 1.59 ms, total: 4.96 ms\n",
      "Wall time: 2.92 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(20.801914, dtype=float32)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grad_log_post(theta_true)[0].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `block_until_ready()` and jit\n",
    "\n",
    "- first time slow: compiles. After that it's fast\n",
    "\n",
    "### why need `block_until_ready()`?\n",
    "- [Asynchronous dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html): Jax will return control to the Python program before finishing its operation\n",
    "- call val_and_grad, but block only the value: faster than blocking the gradient. I'm guessing this is because the gradient is not yet evaluated\n",
    "\n",
    "\n",
    "**Question:** `myarray.block_until_ready()` gives a different timing than `myarray[0].block_until_ready()`. I don't know why!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.37 ms, sys: 2.09 ms, total: 6.45 ms\n",
      "Wall time: 3.67 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(20.801914, dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grad_log_post(theta_true)[0].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 ms, sys: 3.46 ms, total: 18.9 ms\n",
      "Wall time: 14.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(-950.9842, dtype=float32)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just call the log_post\n",
    "%time log_post(theta_true).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray(-950.9842, dtype=float32),\n",
       " DeviceArray([ 20.801914 ,  14.804819 , -18.99264  ,   8.012843 ,\n",
       "               -4.8643513,  21.087633 ,  -2.0005052,   6.074416 ,\n",
       "                4.3361273,  -6.395213 ], dtype=float32))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_and_grad_log_post(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 576 µs, sys: 104 µs, total: 680 µs\n",
      "Wall time: 454 µs\n"
     ]
    }
   ],
   "source": [
    "# block the value of the log_post\n",
    "%time a = val_and_grad_log_post(theta_true)[0].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 ms, sys: 1.35 ms, total: 4.61 ms\n",
      "Wall time: 2.74 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(20.801914, dtype=float32)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# block the 0th element of the gradient array\n",
    "%time val_and_grad_log_post(theta_true)[1][0].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 6 µs, total: 29 µs\n",
      "Wall time: 34.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(-950.9842, dtype=float32)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time a.block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### when does jit compile the function?\n",
    "\n",
    "- The compiler looks at the *shapes* of the inputs, not the values, so if you pass in an array of different shape/type, it'll recompile. \n",
    "- See [this talk](https://slideslive.com/38923687/jax-accelerated-machinelearning-research-via-composable-function-transformations-in-python) at 24:35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. compare to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def onp_loglikelihood(theta, x_val, y_val):\n",
    "    return -onp_logsumexp(onp.array([0., (1.-2.*y_val)*onp.dot(theta, x_val)]))\n",
    "\n",
    "def onp_grad_loglikelihood(theta, x_val, y_val):\n",
    "    denominator = 1 + onp.exp((1-2*y_val)*onp.dot(theta, x_val))\n",
    "    return -(1-2*y_val)*x_val*onp.exp((1-2*y_val)*onp.dot(theta, x_val))/denominator\n",
    "\n",
    "def onp_log_prior(theta):\n",
    "    return -(0.5/10)*onp.dot(theta,theta)\n",
    "\n",
    "\n",
    "def onp_log_post(theta):\n",
    "    return onp_log_prior(theta) + onp.sum([onp_loglikelihood(theta, X[idx,:], y_data[idx]) for idx in range(len(y_data))])\n",
    "\n",
    "def onp_grad_log_post(theta):\n",
    "    return -(0.5/5)*theta + onp.sum([onp_grad_loglikelihood(theta, X[idx,:], y_data[idx]) for idx in range(len(y_data))], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check that they're the same as the Jax functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-950.9841866205513\n",
      "-950.9842\n"
     ]
    }
   ],
   "source": [
    "print(onp_log_post(theta_true))\n",
    "      \n",
    "print(log_post(theta_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.80200821  14.80479718 -18.99266289   8.01293391  -4.86431491\n",
      "  21.08752174  -2.00050171   6.07437987   4.33613178  -6.39520779]\n",
      "\n",
      " [ 20.801914   14.804819  -18.99264     8.012843   -4.8643513  21.087633\n",
      "  -2.0005052   6.074416    4.3361273  -6.395213 ]\n"
     ]
    }
   ],
   "source": [
    "print(onp_grad_log_post(theta_true))\n",
    "\n",
    "print(\"\\n\", grad_log_post(theta_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmarks\n",
    "\n",
    "Jax is 2 orders of magnitude faster than numpy in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 483 ms, sys: 62.2 ms, total: 545 ms\n",
      "Wall time: 493 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-950.9841866205513"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time onp_log_post(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 ms, sys: 3.35 ms, total: 18.3 ms\n",
      "Wall time: 13.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(-950.9842, dtype=float32)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time log_post(theta_true).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 231 ms, sys: 59.1 ms, total: 291 ms\n",
      "Wall time: 239 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 20.80200821,  14.80479718, -18.99266289,   8.01293391,\n",
       "        -4.86431491,  21.08752174,  -2.00050171,   6.07437987,\n",
       "         4.33613178,  -6.39520779])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time onp_grad_log_post(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.53 ms, sys: 2.32 ms, total: 6.84 ms\n",
      "Wall time: 3.98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(20.801914, dtype=float32)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grad_log_post(theta_true)[0].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradient descent\n",
    "\n",
    "- see this [blog post](https://ruder.io/optimizing-gradient-descent/) for an overview of gradient descent methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised param: [ 5.690995    1.3139335   3.0528789   7.1384883   5.97641    -3.0390542\n",
      "  3.0444841  -0.4649384  -0.32056868  1.2873008 ]\n",
      "\n",
      "\n",
      "True value of theta: [ 5.57842333  1.2654082   3.09504126  7.0863265   5.90573691 -3.09042401\n",
      "  3.00444338 -0.47863352 -0.32640667  1.29842647]\n"
     ]
    }
   ],
   "source": [
    "num_iters = 500\n",
    "learning_rate = 1e-3\n",
    "log_post_list = []\n",
    "\n",
    "\n",
    "param = onp.zeros(theta_true.shape)\n",
    "\n",
    "for i in range(num_iters):\n",
    "    param_log_post, param_grad =  val_and_grad_log_post(param)\n",
    "    log_post_list.append(param_log_post)\n",
    "    \n",
    "    # There's no minus sign as we're optimising the log_posterior, not the loss\n",
    "    param = param + learning_rate*param_grad \n",
    "    \n",
    "    \n",
    "print(f\"Optimised param: {param}\")\n",
    "print(\"\\n\")\n",
    "print(f\"True value of theta: {theta_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x213d43c70>]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
